{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j1sk1ss/j1sk1ss/blob/main/ITcup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdLxyDehoMHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "781bf955-b6b6-46e5-df54-011ee4c105b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtJ1UAq7maQi",
        "outputId": "4cc7681a-1cb5-4490-fe77-f167b963bc95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHkxcP-HmJ2g",
        "outputId": "65ccef86-5bf0-4b92-fa8a-6d2291b2ffa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "import torch\n",
        "import string\n",
        "import transformers\n",
        "import gensim\n",
        "from transformers import DistilBertModel, DistilBertTokenizer, logging\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFkWKMQ-mnMh"
      },
      "outputs": [],
      "source": [
        "with open(\"drive/MyDrive/ITcup/ranking_train.jsonl\", \"r\") as f:\n",
        "    data = [json.loads(line) for line in f]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gA-7e_kBuqjs"
      },
      "outputs": [],
      "source": [
        "data=data[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq4q-YPA_XmN"
      },
      "outputs": [],
      "source": [
        "stop_words = stopwords.words('english')\n",
        "for i in range(len(stop_words)):\n",
        "  stop_words[i] = \"\".join([char for char in stop_words[i] if char not in \"'\"])\n",
        "\n",
        "porter = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3YHkRwJmw5R",
        "outputId": "fb10ec3a-19e8-461c-b792-7b6dd30ce08f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtYvRivE9pHB"
      },
      "outputs": [],
      "source": [
        "scores   = []\n",
        "for i in range(len(data)):\n",
        "  for j in range(len(data[i]['comments'])):\n",
        "    scores.append(data[i]['comments'][j]['score'])\n",
        "\n",
        "exclamations = []\n",
        "questions = []\n",
        "links = []\n",
        "lengths = []\n",
        "for i in range(len(data)):\n",
        "  avg_com_len=0\n",
        "  for j in range(len(data[i]['comments'])):\n",
        "    avg_com_len += len(data[i]['comments'][j]['text'])\n",
        "  avg_com_len/=5\n",
        "  tmp_link = 0\n",
        "  tmp_length = 0\n",
        "  for j in range(len(data[i]['comments'])):\n",
        "    tmp_length = len(data[i]['comments'][j]['text'])/avg_com_len\n",
        "    tmp_exclamation = data[i]['comments'][j]['text'].count(\"!\")#/tmp_length\n",
        "    tmp_question = data[i]['comments'][j]['text'].count(\"?\")#/tmp_length\n",
        "    if (\"http\" or \"www\") in data[i]['comments'][j]['text']:\n",
        "      tmp_link += 1\n",
        "\n",
        "  exclamations.append(tmp_exclamation)\n",
        "  questions.append(tmp_question)\n",
        "  links.append(tmp_link)\n",
        "  lengths.append(tmp_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pg7Orp0MlJM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(list(zip(scores[:1000], exclamations, questions, links, lengths)), columns =['Score', '!', '?', 'Has Links', 'Length'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCJsYLQHSYBf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0bfbb4cd-7ea9-4c6d-8a88-31952dba725b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f7ce09afdc0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_9c2ce_row0_col0, #T_9c2ce_row1_col1, #T_9c2ce_row2_col2, #T_9c2ce_row3_col3, #T_9c2ce_row4_col4 {\n",
              "  background-color: #b40426;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9c2ce_row0_col1, #T_9c2ce_row0_col3, #T_9c2ce_row0_col4, #T_9c2ce_row1_col0, #T_9c2ce_row1_col2, #T_9c2ce_row3_col2 {\n",
              "  background-color: #3b4cc0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9c2ce_row0_col2 {\n",
              "  background-color: #445acc;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9c2ce_row1_col3, #T_9c2ce_row3_col4 {\n",
              "  background-color: #3c4ec2;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9c2ce_row1_col4 {\n",
              "  background-color: #536edd;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9c2ce_row2_col0 {\n",
              "  background-color: #506bda;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9c2ce_row2_col1 {\n",
              "  background-color: #485fd1;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9c2ce_row2_col3 {\n",
              "  background-color: #455cce;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9c2ce_row2_col4 {\n",
              "  background-color: #6c8ff1;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9c2ce_row3_col0 {\n",
              "  background-color: #3d50c3;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9c2ce_row3_col1 {\n",
              "  background-color: #3e51c5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9c2ce_row4_col0, #T_9c2ce_row4_col3 {\n",
              "  background-color: #4358cb;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9c2ce_row4_col1 {\n",
              "  background-color: #5b7ae5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9c2ce_row4_col2 {\n",
              "  background-color: #688aef;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_9c2ce\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_9c2ce_level0_col0\" class=\"col_heading level0 col0\" >Score</th>\n",
              "      <th id=\"T_9c2ce_level0_col1\" class=\"col_heading level0 col1\" >!</th>\n",
              "      <th id=\"T_9c2ce_level0_col2\" class=\"col_heading level0 col2\" >?</th>\n",
              "      <th id=\"T_9c2ce_level0_col3\" class=\"col_heading level0 col3\" >Has Links</th>\n",
              "      <th id=\"T_9c2ce_level0_col4\" class=\"col_heading level0 col4\" >Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_9c2ce_level0_row0\" class=\"row_heading level0 row0\" >Score</th>\n",
              "      <td id=\"T_9c2ce_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
              "      <td id=\"T_9c2ce_row0_col1\" class=\"data row0 col1\" >-0.042213</td>\n",
              "      <td id=\"T_9c2ce_row0_col2\" class=\"data row0 col2\" >0.035056</td>\n",
              "      <td id=\"T_9c2ce_row0_col3\" class=\"data row0 col3\" >-0.031487</td>\n",
              "      <td id=\"T_9c2ce_row0_col4\" class=\"data row0 col4\" >-0.009955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9c2ce_level0_row1\" class=\"row_heading level0 row1\" >!</th>\n",
              "      <td id=\"T_9c2ce_row1_col0\" class=\"data row1 col0\" >-0.042213</td>\n",
              "      <td id=\"T_9c2ce_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
              "      <td id=\"T_9c2ce_row1_col2\" class=\"data row1 col2\" >0.003894</td>\n",
              "      <td id=\"T_9c2ce_row1_col3\" class=\"data row1 col3\" >-0.025979</td>\n",
              "      <td id=\"T_9c2ce_row1_col4\" class=\"data row1 col4\" >0.070310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9c2ce_level0_row2\" class=\"row_heading level0 row2\" >?</th>\n",
              "      <td id=\"T_9c2ce_row2_col0\" class=\"data row2 col0\" >0.035056</td>\n",
              "      <td id=\"T_9c2ce_row2_col1\" class=\"data row2 col1\" >0.003894</td>\n",
              "      <td id=\"T_9c2ce_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
              "      <td id=\"T_9c2ce_row2_col3\" class=\"data row2 col3\" >0.005149</td>\n",
              "      <td id=\"T_9c2ce_row2_col4\" class=\"data row2 col4\" >0.149402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9c2ce_level0_row3\" class=\"row_heading level0 row3\" >Has Links</th>\n",
              "      <td id=\"T_9c2ce_row3_col0\" class=\"data row3 col0\" >-0.031487</td>\n",
              "      <td id=\"T_9c2ce_row3_col1\" class=\"data row3 col1\" >-0.025979</td>\n",
              "      <td id=\"T_9c2ce_row3_col2\" class=\"data row3 col2\" >0.005149</td>\n",
              "      <td id=\"T_9c2ce_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
              "      <td id=\"T_9c2ce_row3_col4\" class=\"data row3 col4\" >-0.002232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9c2ce_level0_row4\" class=\"row_heading level0 row4\" >Length</th>\n",
              "      <td id=\"T_9c2ce_row4_col0\" class=\"data row4 col0\" >-0.009955</td>\n",
              "      <td id=\"T_9c2ce_row4_col1\" class=\"data row4 col1\" >0.070310</td>\n",
              "      <td id=\"T_9c2ce_row4_col2\" class=\"data row4 col2\" >0.149402</td>\n",
              "      <td id=\"T_9c2ce_row4_col3\" class=\"data row4 col3\" >-0.002232</td>\n",
              "      <td id=\"T_9c2ce_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 280
        }
      ],
      "source": [
        "corr = df.corr()\n",
        "corr.style.background_gradient(cmap='coolwarm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxB82ZXH4-od"
      },
      "outputs": [],
      "source": [
        "for datum in data:\n",
        "  datum['text'] = datum['text'].lower()\n",
        "  datum['text'] = \"\".join([char for char in datum['text'] if char not in string.punctuation])\n",
        "  datum['text'] = word_tokenize(datum['text'])\n",
        "  datum['text'] = [word for word in datum['text'] if word not in stop_words]\n",
        "  #datum['text'] = [porter.stem(word) for word in datum['text']]\n",
        "  #datum['text'] = ' '.join(datum['text'])\n",
        "  for comment in datum['comments']:\n",
        "    comment['text'] = comment['text'].lower()\n",
        "    comment['text'] = \"\".join([char for char in comment['text'] if char not in string.punctuation])\n",
        "    comment['text'] = word_tokenize(comment['text'])\n",
        "    comment['text'] = [word for word in comment['text'] if word not in stop_words]\n",
        "    #comment['text'] = [porter.stem(word) for word in comment['text']]\n",
        "    #comment['text'] = ' '.join(comment['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_mn-CKBm4ES"
      },
      "outputs": [],
      "source": [
        "texts = []\n",
        "comments = []\n",
        "\n",
        "for i in range(len(data)):\n",
        "  texts.append(data[i]['text'])\n",
        "  for j in range(len(data[i]['comments'])):\n",
        "    comments.append(data[i]['comments'][j]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNySHN8CJoGF"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api\n",
        "model = api.load(\"glove-wiki-gigaword-100\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqAy7F5j-pC9"
      },
      "outputs": [],
      "source": [
        "similarity=[]\n",
        "\n",
        "sentences=comments[0:5]\n",
        "target_sentence=texts[0]\n",
        "\n",
        "for i in range(len(texts)):\n",
        "  sentences_similarity = np.zeros(len(sentences))\n",
        "  w2v_vocab = model.vocab.keys()\n",
        "  sentences=comments[5*i:5+5*i]\n",
        "  target_sentence=texts[i]\n",
        "  for idx, sentence in enumerate(sentences):\n",
        "    sentence_words = [w for w in sentence if w in w2v_vocab]\n",
        "    if (len(sentence_words) == 0):\n",
        "      sentence_words=['fortune']\n",
        "    target_sentence_words = [w for w in target_sentence if w in w2v_vocab]\n",
        "    if (len(target_sentence_words) == 0):\n",
        "      target_sentence_words=['fortune']\n",
        "    sim = model.n_similarity(target_sentence_words, sentence_words)\n",
        "    sentences_similarity[idx] = sim\n",
        "\n",
        "  result = list(zip(sentences_similarity))\n",
        "  #result.sort(key=lambda item:item[0], reverse=True)\n",
        "  for i in range(5):\n",
        "    similarity+=result[i]\n",
        "  #print(\"Target:\", target_sentence)\n",
        "  #print(result[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#similarity_normalized = similarity.copy()\n",
        "#for i in range(int(len(similarity))):\n",
        "#  for j in range(5):\n",
        "#    similarity_normalized[5*i+j] = similarity[5*i+j] / max(similarity[5*i:5+5*i])\n",
        "#df['Similarity_normalized'] = similarity_normalized"
      ],
      "metadata": {
        "id": "Ay35_T5MTM9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "DSL0-oihdgVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ4lhWwZLNfe"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(128, 64),\n",
        "            nn.LeakyReLU(0.01),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(64,32),\n",
        "            nn.LeakyReLU(0.01),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(32,16),\n",
        "            nn.LeakyReLU(0.01),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(16,5)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "w2v_vocab = model.vocab.keys()"
      ],
      "metadata": {
        "id": "6r_fEZK2fwW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comms=[]\n",
        "for i in range(len(comments)):\n",
        "  if (comments[i] and comments[i][0] in w2v_vocab):\n",
        "    cur = model.wv.get_vector(comments[i][0])\n",
        "    for j in range(len(comments[i])):\n",
        "      if (comments[i][j] and comments[i][j] in w2v_vocab):\n",
        "        cur = np.sum([cur, model.wv.get_vector(comments[i][j])], axis = 0)\n",
        "  comms.append(cur/(len(comments[i])))"
      ],
      "metadata": {
        "id": "_43TQacNtE9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beed75a9-9638-4188-a1e2-f0e41ab8d52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-288-c29fed2aa1ce>:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  cur = model.wv.get_vector(comments[i][0])\n",
            "<ipython-input-288-c29fed2aa1ce>:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  cur = np.sum([cur, model.wv.get_vector(comments[i][j])], axis = 0)\n",
            "<ipython-input-288-c29fed2aa1ce>:8: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  comms.append(cur/(len(comments[i])))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "posts=[]\n",
        "for i in range(len(texts)):\n",
        "  if (texts[i] and texts[i][0] in w2v_vocab):\n",
        "    cur = model.wv.get_vector(texts[i][0])\n",
        "    for j in range(len(texts[i])):\n",
        "      if (texts[i][j] and texts[i][j] in w2v_vocab):\n",
        "        cur = np.sum([cur, model.wv.get_vector(texts[i][j])], axis = 0)\n",
        "  posts.append(cur/(len(texts[i])))"
      ],
      "metadata": {
        "id": "sczZHjTYvjlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44aa9ab4-fbc6-4d3b-c522-933b948af80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-289-a55d8622a957>:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  cur = model.wv.get_vector(texts[i][0])\n",
            "<ipython-input-289-a55d8622a957>:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  cur = np.sum([cur, model.wv.get_vector(texts[i][j])], axis = 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expected = [\n",
        "([1,0,0,0,0],\n",
        "[0,1,0,0,0],\n",
        "[0,0,1,0,0],\n",
        "[0,0,0,1,0],\n",
        "[0,0,0,0,1],)*(int(len(comms)/5)+5)\n",
        "]\n",
        "expected[0] = expected[0][:len(comms)]"
      ],
      "metadata": {
        "id": "B7NBu0sQ2O08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "fPcsJMTq_1AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4klWpYUG9Mu",
        "outputId": "2cbaaf9c-7085-4808-d6ef-31cdb7bb33af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_13oVFMH7RQ",
        "outputId": "76ff7eec-f76e-4db5-ab9b-86a6f5812a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model = NeuralNetwork()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(5):\n",
        "  for i in tqdm(range(len(expected[0]))):\n",
        "    outputs = model.forward(torch.FloatTensor(np.concatenate((comms[i], np.array([similarity[i]] * 28)))))\n",
        "    expected_flat = torch.FloatTensor(expected[0][i]).flatten()\n",
        "    loss = loss_fn(outputs, expected_flat)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rnRnmiY_hpe",
        "outputId": "ab982063-06aa-4bb3-e139-f266ae8e8c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:05<00:00, 973.54it/s] \n",
            "100%|██████████| 5000/5000 [00:04<00:00, 1092.19it/s]\n",
            "100%|██████████| 5000/5000 [00:10<00:00, 471.76it/s]\n",
            "100%|██████████| 5000/5000 [00:11<00:00, 435.22it/s]\n",
            "100%|██████████| 5000/5000 [00:04<00:00, 1132.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(comms)):\n",
        "  outputs = model.forward(torch.FloatTensor(comms[i]))\n",
        "  expected_flat = torch.FloatTensor(expected[0][i]).flatten()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "u18X6ZIxJBtW",
        "outputId": "586a0c8a-213d-4cf5-afa5-4d4aee825d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-295-f9e7a50848b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mexpected_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-287-0d56c5a938ed>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_relu_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x100 and 128x64)"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}